# AI Assistant with Dual Services - PowerPoint Presentation

## Slide 1: Title Slide
**AI Assistant with Dual Services**
*A Modern Fullstack AI Application*

- **Subtitle**: Intelligent Chat & Web Research Platform
- **Technologies**: React + LangGraph + Multi-LLM Support
- **Architecture**: Dual Backend Services for Optimal Performance

---

## Slide 2: Project Overview
**What is this project?**

A comprehensive AI assistant application featuring:
- **AI Chat Service**: Fast AI conversations (1-5s response)
- **AI Search Service**: Web-powered research with citations (10-30s response)
- **Multi-LLM Support**: Gemini, DeepSeek with intelligent hybrid architecture
- **Modern UI**: React frontend with dark/light themes

*[Screenshot needed: Main application interface showing both chat and search modes]*

---

## Slide 3: Key Features & Capabilities
**ğŸ¤– AI Capabilities**
- Multi-LLM Provider Support (Gemini, DeepSeek)
- Dynamic search query generation
- Integrated web research via Google Search API
- Reflective reasoning for knowledge gap analysis
- Citation-rich answers from web sources
- Cost optimization through smart provider selection

**ğŸ¨ User Experience**
- Dual service architecture for different use cases
- Session management with conversation history
- Favorites and bookmarking system
- Export functionality (HTML/Markdown)
- Responsive design with theme support

---

## Slide 4: Architecture Overview
**Dual Service Architecture**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend      â”‚    â”‚  SimAI Chat â”‚    â”‚   AI Search     â”‚
â”‚  (Port 5174)    â”‚    â”‚  (Port 3000)    â”‚    â”‚  (Port 2024)    â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ SiAI Chatâ—„â”¼â”€â”€â”€â”€â”¼â–ºâ”‚ FastAPI     â”‚ â”‚    â”‚ â”‚ LangGraph   â”‚ â”‚
â”‚ â”‚ Component   â”‚ â”‚    â”‚ â”‚ + LLM       â”‚ â”‚    â”‚ â”‚ + Web       â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚    â”‚ â”‚ Clients     â”‚ â”‚    â”‚ â”‚ Search      â”‚ â”‚
â”‚                 â”‚    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ â”‚ AI Search   â”‚â—„â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ â”‚ Component   â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Benefits:**
- Independent scaling and deployment
- Service-specific optimizations
- Clear separation of concerns

---

## Slide 5: Frontend Technology Stack
**React + Modern UI Framework**

**Core Technologies:**
- **React 19** with TypeScript
- **Vite** for fast development and building
- **Tailwind CSS** for styling
- **Shadcn UI** for component library
- **React Router** for navigation

**Key Libraries:**
- **React Markdown** with syntax highlighting
- **Lucide React** for icons
- **HTML2Canvas** for screenshot functionality
- **Session Management** for conversation history

*[Screenshot needed: Frontend component structure or UI components]*

---

## Slide 6: Backend Architecture - AI Chat Service
**FastAPI + Direct LLM Integration**

**Port 3000 - AI Chat Service**
- **FastAPI** web framework
- **Direct LLM clients** (Gemini, DeepSeek)
- **Session management** with conversation history
- **Provider API** for dynamic model discovery

**Key Features:**
- Fast response times (1-5 seconds)
- Multiple LLM provider support
- Temperature and model selection
- Conversation context preservation

**API Endpoints:**
- `GET /health` - Health check
- `GET /api/providers` - Available models
- `POST /api/chat` - Chat endpoint

---

## Slide 7: Backend Architecture - AI Search Service
**LangGraph + Web Research Agent**

**Port 2024 - AI Search Service**
- **LangGraph** for agent orchestration
- **Google Search API** integration
- **Multi-step reasoning** workflow
- **Citation management** system

**Agent Workflow:**
1. **Generate Initial Queries** - Based on user input
2. **Web Research** - Search and gather information
3. **Reflection & Analysis** - Identify knowledge gaps
4. **Iterative Refinement** - Follow-up searches if needed
5. **Synthesize Answer** - With citations and sources

*[Screenshot needed: Agent workflow diagram or LangGraph visualization]*

---

## Slide 8: LLM Provider Support
**Multi-Provider Architecture**

**Gemini Models (Google)**
- âœ… **FREE**: `gemini-1.5-flash`, `gemini-1.5-flash-8b`
- ğŸ’° **PAID**: `gemini-2.5-pro`, `gemini-2.5-flash`, `gemini-2.0-flash`
- Features: Fast, multimodal, web search capabilities

**DeepSeek Models**
- ğŸ’° **PAID**: `deepseek-chat`, `deepseek-coder`
- Features: Cost-effective, Chinese language support, code specialization

**Hybrid Architecture:**
- **Web Search**: Gemini (required for Google Search API)
- **Analysis & Reasoning**: DeepSeek (cost-effective)
- **Best of both worlds**: Real-time search + cost optimization

---

## Slide 9: Key Technical Features
**Advanced Functionality**

**ğŸ” Intelligent Search**
- Dynamic query generation using AI
- Multi-step web research process
- Knowledge gap identification and refinement
- Citation tracking and source management

**ğŸ’¾ Session Management**
- Unique session IDs for conversation tracking
- History sidebar with session grouping
- Context-aware questioning within sessions
- Export and favorite functionality

**ğŸ¨ User Interface**
- Dark/light theme support
- Responsive design for all screen sizes
- Syntax highlighting for code blocks
- Scrollable content with fixed input areas

---

## Slide 10: Development & Deployment
**Developer Experience**

**Development Setup:**
- Hot-reloading for both frontend and backend
- Comprehensive test suite
- Multi-language documentation (English/Chinese)
- Centralized configuration management

**Deployment Options:**
- **Development**: Separate service startup
- **Production**: Docker containerization
- **Dependencies**: Redis + PostgreSQL for LangGraph
- **Scaling**: Independent service scaling

**Configuration:**
```bash
# Environment Variables
GEMINI_API_KEY="your_key"
DEEPSEEK_API_KEY="your_key"
LLM_PROVIDER=auto
USE_HYBRID_ARCHITECTURE=true
```

---

## Slide 11: Project Structure
**Organized Codebase**

```
project/
â”œâ”€â”€ frontend/                 # React application
â”‚   â”œâ”€â”€ src/components/      # UI components
â”‚   â”œâ”€â”€ src/config/         # API configuration
â”‚   â””â”€â”€ src/utils/          # Utilities
â”œâ”€â”€ backend/                 # Python backend
â”‚   â”œâ”€â”€ src/agent/          # LangGraph agent
â”‚   â”œâ”€â”€ src/simai_chat_server  # Chat service
â”‚   â””â”€â”€ src/config.py       # Configuration
â”œâ”€â”€ docs/                   # Documentation
â””â”€â”€ docker-compose.yml      # Production deployment
```

**Key Components:**
- **AIChat.tsx**: Chat interface component
- **AISearch.tsx**: Search interface component
- **graph.py**: LangGraph agent implementation
- **ai_chat_server.py**: FastAPI chat service

---

## Slide 12: Future Enhancements
**Roadmap & Improvements**

**ğŸ”® Planned Features:**
- **Service Discovery**: Dynamic port discovery and health monitoring
- **Enhanced Model Management**: Performance metrics and cost tracking
- **Advanced UI Features**: Model comparison, conversation export/import
- **Real-time Indicators**: Service status and response time monitoring

**ğŸ—ï¸ Architecture Improvements:**
- Microservices migration readiness
- Load balancing for multiple instances
- Enhanced error handling and recovery
- Performance optimization and caching

**ğŸ“Š Analytics & Monitoring:**
- Usage analytics and optimization suggestions
- Cost tracking per provider/model
- Response time and quality metrics

---

## Slide 13: Demo & Screenshots
**Live Application Demonstration**

*[Multiple screenshots needed:]*
1. **Main Interface**: Showing sidebar with chat/search modes
2. **AI Chat**: Fast AI conversation example
3. **AI Search**: Web research with citations
4. **History Sidebar**: Session management interface
5. **Settings Panel**: Model and provider selection
6. **Dark/Light Theme**: Theme switching demonstration
7. **Mobile Responsive**: Mobile view of the application

**Key Demo Points:**
- Fast chat responses vs comprehensive search
- Model switching and provider selection
- Session history and favorites
- Export functionality
- Theme switching

---

## Slide 14: Technical Achievements
**What Makes This Project Special**

**âœ… Architecture Excellence**
- Clean separation between chat and search services
- Scalable microservices-ready design
- Dynamic configuration without hardcoded values

**âœ… User Experience**
- Sub-5-second chat responses
- Rich search results with citations
- Intuitive interface with modern design
- Comprehensive session management

**âœ… Developer Experience**
- Hot-reloading development environment
- Comprehensive documentation
- Easy deployment with Docker
- Extensible provider architecture

**âœ… Cost Optimization**
- Smart provider selection for different tasks
- Hybrid architecture for optimal performance/cost
- Support for both free and paid models

---

## Slide 15: Conclusion
**AI Assistant with Dual Services**

**ğŸ¯ Project Summary**
A modern, scalable AI assistant that combines fast chat capabilities with comprehensive web research, built with cutting-edge technologies and best practices.

**ğŸš€ Key Strengths**
- **Performance**: Dual architecture for optimal response times
- **Flexibility**: Multi-provider LLM support with cost optimization
- **Usability**: Intuitive interface with comprehensive features
- **Scalability**: Microservices-ready architecture

**ğŸ”— Technologies Used**
- **Frontend**: React, TypeScript, Tailwind CSS, Vite
- **Backend**: Python, FastAPI, LangGraph, Google Search API
- **AI**: Gemini, DeepSeek, Multi-LLM architecture
- **Deployment**: Docker, Redis, PostgreSQL

**Thank you for your attention!**
*Questions & Discussion*
